layout: page
title: "Step-By-Step Guide"
permalink: /guide

This guide will walk you through the steps of developing MAS middleware. The development of these
small programs has a big impact -- allowing you to plug your service into the DiSSCo architecture.

# 1. Data Modelling

Before you develop adapt your service to DiSSCo, you need to think about the end result. What value
does your service add?

Some questions to consider:

- Does your service target digital specimens or media objects?
- If your service returns textual information, can its results be best mapped to terms or
  classes in OpenDS? Or does your service apply information to the entire target?
- If your service returns information or predictions about a region, how can its region be mapped to
  the region of interest selector in the annotation data model?
- What information does your service need to run? What fields in openDS can you send to your
  service?
- Does your MAS return the same output for the same input every time? Is it a service that makes
  sense to apply its result to multiple resources at the same time? Then you may want to consider
  batching annotations. See [Batching Annotations](#batching-annotations) for more information.

**You can find more about openDS on its [Terms Site](https://terms.dissco.tech/)**

## Data Schemas

JSON Schemas are hosted on our [schemas site](https://schemas.dissco.tech/schemas/). Refer to the
schemas site for the most up to-date information.

### Requests

Requests sent to the MAS will follow the following structure:

```json
{
  "jobId": "502f0fea-acce-4299-a138-2383faa7c9f9",
  "object": {
    // digital specimen OR digital media following OpenDS specification
  },
  "batchingRequested": true
}
```

`jobId` is a UUID generated by DiSSCo to track job state (e.g. running, failed, scheduled) for the
user. It must be returned unaltered to the DiSSCo architecture.

`batchingRequested`: While [batching](#batching-annotations) may reduce computational load, a MAS
must be specifically designed with it in mind, as it requires additional metadata to support this
functionality.

### Responses

The response from the MAS to the DiSSCo Architecture must follow the following schema:

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://schemas.dissco.tech/schemas/developer-schema/annotation/0.4.0/annotation-processing-event.json",
  "type": "object",
  "description": "Schema specific to Services (MAS or DiSSCover) providing information to DiSSCo's annotation processing service.",
  "properties": {
    "jobId": {
      "type": "string",
      "description": "Handle of the job record, if the annotation was produced by a Machine Annotation Service"
    },
    "annotations": {
      "type": "array",
      "description": "List of annotations produced by the MAS",
      "items": {
        "$ref": "https://schemas.dissco.tech/schemas/developer-schema/annotation/0.4.0/annotation-processing-request.json"
      }
    },
    "batchMetadata": {
      "type": "array",
      "description": "Object containing batch information, if result is a batch",
      "items": {
        "$ref": "https://schemas.dissco.tech/schemas/developer-schema/annotation/0.4.0/annotation-batch-metadata.json"
      }
    }
  },
  "additionalProperties": false,
  "required": [
    "jobId",
    "annotations"
  ]
}
```

- `jobId` is the unaltered jobId provided to the MAS in the request.
- `annotations` is the list of annotations produced by the MAS. A MAS may produce multiple
  annotations per job on the same object. The annotations must follow
  the [annotation schema for MAS developers](https://schemas.dissco.tech/schemas/developer-schema/annotation/0.4.0/annotation-processing-request.json)

### Batching Annotations

Note: Batching is still an experimental feature. Batching may produce an unintended number of
annotations without the proper batch metadata. Use with caution.

MAS providers can opt to enable their service for batch annotations, a feature particularly useful
for services that can be applied to multiple specimens simultaneously. Batch annotations help reduce
computational overhead by allowing DiSSCo to identify resources with identical input data. Instead
of running the MAS separately for each resource, DiSSCo applies the annotation across all relevant
resources, streamlining the process and conserving resources. For example, a MAS may take locality
information from a specimen and return a set of georeferenced coordinates. If this service is
batched, then all specimens with the same locality string will receive the same coordinate
annotation, with the original calculation only made once. Batching reduces load on the
original service, as it does not need to redundant calculations.

To enable this process, MASs can include batchMetadata in their response. The information provided
in the batchMetadata allows DiSSCo to generate search queries that identify resources matching the
criteria originally used to produce the annotation. This allows the system to apply the same
annotation across multiple resources without needing to re-run the MAS for each individual object.

Batching is NOT suited for services which may produce different responses for the same input, e.g.
AI services. It is also not suited for services for which it doesn't make sense to apply to multiple
services. For instance, a service which finds identifiers in other infrastructures can not apply the
same result to different objects, as the result of the service is by nature unique to its original
target.

The schema for batchMetadata can be found here, and it includes the following key fields:

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://schemas.dissco.tech/schemas/developer-schema/annotation/0.4.0/annotation-batch-metadata.json",
  "properties": {
    "ods:placeInBatch": {
      "description": "For batching only. Links batch metadata to specific annotations in an event. Value must correspond to an annotation's ods:placeInBatch",
      "type": "integer"
    },
    "searchParams": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "inputField": {
            "type": "string",
            "description": "JsonPath (mixed notation) of field used to base annotation reasoning on. Indexes must be wildcards",
            "examples": [
              "digitalSpecimenWrapper.occurrences[*].location.dwc:country"
            ]
          },
          "inputValue": {
            "type": "string",
            "description": "Value stored at the field indicated in inputField",
            "examples": [
              "Netherlands"
            ]
          }
        },
        "required": [
          "inputField",
          "inputValue"
        ],
        "additionalProperties": false
      },
      "minItems": 1
    }
  },
  "required": [
    "ods:placeInBatch",
    "searchParams"
  ],
  "additionalProperties": false
}
```

`placeInBatch`: Integer that indicates which annotation this batch metadata corresponds to. There
MUST be a corresponding "placeInBatch" value in one annotation in the event. If more than one
annotation
have the same placeInBatch value, only the first annotation will be used to create a base
annotation.

`inputField`: The full JSONPath of the field used to generate MAS annotation, in JSONPath block
notation,
e.g. ['ods:DigitalSpecimen']['ods:hasIdentifications'][*]['ods:hasTaxonIdentifications'][*]['dwc:taxonRank'].
Array indexes must be omitted - instead, use wildcards.

`inputValue`: value stored at the specified JSONPath.

Batching can only be done if the MAS sends annotations of one Type of object in one event - either
Digital Specimens OR Media Objects.

# 2. Development

Once you know your inputs and outputs of your MAS middleware, you're ready to start developing.

DiSSCo communicates with MASs through a Kafka queue. Kafka is an asynchronous messaging system. It
allows events, such as tasks or data updates, to be sent between systems in a highly reliable and
scalable way. When a user schedules a MAS via the DiSSCover platform, DiSSCo dispatches a Kafka
message to the designated MAS, initiating the annotation process.

Kafka topics are unique names used to organize messages. Kafka producers write data to topics, and
consumers read data from topics. You will need to set up a kafka topic provided by
the DiSSCo team. Your MAS will send its result as a kafka message of the same topic. It is best to
store this topic name in an environment variable.

To get started on development, you can fork
the [MAS Template](https://github.com/DiSSCo/machine-annotation-service-template) on GitHub. The
`annotation` package contains code that will format a result forom an API to the openDS annotation
model. Two templates are provided: a default template and a batch template.

There are also some functional MASs available
on [GitHub](https://github.com/diSSCo/demo-enrichment-service-image/) you may use as a reference.

## Running Endpoint

As an added value service to the user, DiSSCo tracks the progress of a job through states:

- SCHEDULED
- RUNNING
- COMPLETED
- FAILED

When a MAS receives a message, it is strongly recommended to call the `/running` endpoint. This
indicates to DiSSCo the message has been received by the mas and the job is running. DiSSCo can then
inform the user of the development.

The endpoint has no body, and is reached at `/api/mjr/v1/{JOB-ID}`.

In deployment, DiSSCo automatically populates the `RUNNING_ENDPOINT` environmental variable with the
correct endpoint, depending on the environment is being run on.

- Test: https://dev.dissco.tech/api/mjr/v1/{JOB-ID}
- Acceptance:  https://sandbox.dissco.tech/api/mjr/v1/{JOB-ID}
- Production: https://api.dissco.eu/mjr/v1/{JOB_ID}

# 3. Registration and Deployment

When the MAS middleware is finished, the DiSSCo team will help you register your Machine Annotation
Service. The Orchestration Service is a DiSSCo service that creates deployment files for the MAS
middleware. Once a MAS is registered, it will be available in the DiSSCo test environment. To
register a MAS, the DiSSCo team needs the following information.

## Valid Dockerfile

When you've completed developing your MAS middleware, you're ready to containerize it. Make sure
there is a valid Docker file in the source code. The DiSSCo team will build the image and push it to
the DiSSCo Elastic Container Registry.

Note: DiSSCo is only responsible for the deployment of the MAS middleware. The primary service
remains the responsibility of the developer.

## Environmental Variables and Secrets

In the MAS data model there is space for both environmental variables and secrets. The
environmental variables can be used to set parameters for an algorithm or feature toggle specifics
parts of the MAS. The **environmental variables should not be used to put in secret variables**.
They are not encrypted and can be read by anybody.

For secret variables, we encrypt the values and inject them into the application. For this, the
DiSSCo development team is required add the secret to the DiSSCo Secret Store on AWS. This is a
manual action which hasn't been automated (yet).

The secret should first be securely provided to the DiSSCo development team, *along with the name of
the variable*. For the transfer of the secrets, several options are available, all of which should
include a two-factor authentication.
Examples include:

- A zip-file can be secured with a password and send via email. The password should then come
  through a different medium
  such as a text message or a chat message.
- It is also possible to use a website as https://onetimesecret.com/ preferably with a passphrase
  which is provided through a different
  medium.

The DiSSCo team will then insert the secret into our Secret Store. The variable can then be injected
into the program as an environmental variable.

### Example

Alice wants to send the DiSSCo team a password used in her code. She has the following `.env` file:

```text
API_KEY=2bbd58fe-2654-4049-be60-4f1302a76c53
API_ENDPOINT=https://api.code.com/specimens
```

Alice sends the value of `API_KEY` through https://onetimesecret.com/, and includes the password in
another email. Because it is not sensitive information, she can send the value of `API_ENDPOINT` by
email. At the same time, she also informs the DiSSCo of the name of the variables.

The DiSSCo team inserts the `API_KEY` in the secret store. Registering the MAS, the DiSSCo team
includes the environmental variables and secrets, which

The resulting kubernetes file will thus have all the information needed to access the secret and
inject it into the running service.

```yaml
containers:
  env:
    - name: API_ENDPOINT
        value: https://api.code.com/specimens
                 - name: API_KEY
                 valueFrom:
                   secretKeyRef:
                     key: alice-api-key
                     name: mas-secrets
```

## Filters

Upon registration, MAS providers have the option to set filters that determine which objects their
MAS will annotate. Filters are a valuable tool for ensuring that only relevant digital objects
are processed by the MAS. For example, if a MAS is specifically designed to annotate media objects,
applying a filter such as `ods:type = "https://doi.org/21.T11148/bbad8c4e101e8af01115"` will exclude
any non-relevant objects, ensuring that the MAS only operates on the appropriate data.

When a filter is including on a MAS, the MAS will only be available for resources that meet the
specified criteria. Therefore, **it is strongly recommended to include filters** to optimize the
accuracy and efficiency of the annotation process. This targeted approach helps maintain the quality
and relevance of annotations generated within the DiSSCo ecosystem.

Please provide filters in JSON Path Block notation.

## Batching Permitted

MAS providers can opt to enable their service for batch annotations, a feature particularly useful
for services that can be applied to multiple specimens simultaneously. Batch annotations help reduce
computational overhead by allowing DiSSCo to identify resources with identical input data. Instead
of running the MAS separately for each resource, DiSSCo applies the annotation across all relevant
resources, streamlining the process and conserving resources.

However, it's important to note that a MAS must be specifically designed with batching in mind, as
it requires additional metadata to support this functionality. For detailed guidance on developing a
batch-enabled MAS, please refer to the [batching](#batching-annotations) section earlier in this
guide.

## Other Metadata

Additional metadata is useful for providing users with more information about the service. Please
provide as many of the following terms as possible.

- name of the service (required)
- description
- creativeWorkStatus - The current status of the service
- codeRepository - Link to code base of MAS
- programmingLanguage
- serviceAvailability - Availability commitment of the service provider as described in the SLA
- maintainer (Follows Agent data model)
- license
- Contact point (Description, email, url, phone)
- SLA Documentation

See
the [MAS JSON Schema](https://schemas.dissco.tech/schemas/fdo-type/machine-annotation-service/latest/machine-annotation-service.json)
or [MAS Terms Site](https://terms.dissco.tech/machine-annotation-service-terms)
for more information on the MAS data model.

# Conclusion

Thank you for your commitment to enhancing the DiSSCo community through the development and
deployment of MASs. By following the guidelines outlined in this guide, you are playing a crucial
role in advancing biodiversity research. Whether through novel machine learning approaches,
georeferencing tools, or automated data checks, the contribution of help improve natural science
collection data quality across Europe. Machine Annotation Services not only support ongoing
research, but also empower the scientific community to engage in meaningful post-publication
curation. This collaborative approach enhances the value of digitized collections, ensuring they
remain relevant and up to-date long after their initial publication.